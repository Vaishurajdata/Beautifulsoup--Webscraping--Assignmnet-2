{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc58bca5",
   "metadata": {},
   "source": [
    "# 1.FINDING HEADER TAGS FOR WIKIPEDIA TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3c34cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0a0813c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n",
      "Navigation menu\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "Namespaces\n",
      "\n",
      "\n",
      "Views\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "Navigation\n",
      "\n",
      "\n",
      "Contribute\n",
      "\n",
      "\n",
      "Tools\n",
      "\n",
      "\n",
      "Print/export\n",
      "\n",
      "\n",
      "In other projects\n",
      "\n",
      "\n",
      "Languages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "\n",
    "url = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(url.text, 'html.parser')\n",
    "story = soup.find_all(['h1', 'h2','h3'])\n",
    "for i in story:\n",
    "    i=i.get_text()\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66640d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I found this headings in wikipedia instead of headers- so the answer may be partially correct or wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff548488",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97a2e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_top_link = \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\"\n",
    "\n",
    "imdb_top_indian_link = \"https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=461131e5-5af0-4e50-bee2-223fad1e00ca&pf_rd_r=YGMQ7QBSZRY8RE39C7KD&pf_rd_s=center-1&pf_rd_t=60601&pf_rd_i=india.toprated&ref_=fea_india_ss_toprated_india_tr_india250_sm\"\n",
    "\n",
    "def find_top_100(link):\n",
    "\n",
    "    imdb_site_data = requests.get(link)\n",
    "    soup_imdb = BeautifulSoup(imdb_site_data.content , \"html.parser\")\n",
    "    scrapedtitles = soup_imdb.find_all('td' , class_ = \"titleColumn\" )\n",
    "    titles = []\n",
    "    for title in scrapedtitles:\n",
    "        title = title.get_text().strip()\n",
    "        titles.append(title)\n",
    "    titles\n",
    "    scrapedratings = soup_imdb.find_all('td' , class_ = \"ratingColumn imdbRating\" )\n",
    "    ratings = []\n",
    "    for rating in scrapedratings:\n",
    "        rating = rating.get_text().strip()\n",
    "        ratings.append(rating)\n",
    "    years = []\n",
    "    for title in titles:\n",
    "        year = title[-5:-1]\n",
    "        years.append(year)\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    data['Title'] = titles\n",
    "    data['Year'] = years\n",
    "    data['Rating'] = ratings\n",
    "\n",
    "    top_imdb_100_movies = data[1:101]\n",
    "    return top_imdb_100_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a91b5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.\\n      The Godfather\\n(1972)</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.\\n      The Dark Knight\\n(2008)</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.\\n      The Godfather Part II\\n(1974)</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.\\n      12 Angry Men\\n(1957)</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.\\n      Schindler's List\\n(1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.\\n      M - Eine Stadt sucht einen Mörder\\n...</td>\n",
       "      <td>1931</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.\\n      North by Northwest\\n(1959)</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.\\n      Vertigo\\n(1958)</td>\n",
       "      <td>1958</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.\\n      Idi i smotri\\n(1985)</td>\n",
       "      <td>1985</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101.\\n      Le fabuleux destin d'Amélie Poulai...</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  Year Rating\n",
       "1                      2.\\n      The Godfather\\n(1972)  1972    9.2\n",
       "2                    3.\\n      The Dark Knight\\n(2008)  2008    9.0\n",
       "3              4.\\n      The Godfather Part II\\n(1974)  1974    9.0\n",
       "4                       5.\\n      12 Angry Men\\n(1957)  1957    8.9\n",
       "5                   6.\\n      Schindler's List\\n(1993)  1993    8.9\n",
       "..                                                 ...   ...    ...\n",
       "96   97.\\n      M - Eine Stadt sucht einen Mörder\\n...  1931    8.3\n",
       "97               98.\\n      North by Northwest\\n(1959)  1959    8.3\n",
       "98                          99.\\n      Vertigo\\n(1958)  1958    8.2\n",
       "99                    100.\\n      Idi i smotri\\n(1985)  1985    8.2\n",
       "100  101.\\n      Le fabuleux destin d'Amélie Poulai...  2001    8.2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_100(imdb_top_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483d249",
   "metadata": {},
   "source": [
    "# 3.  Write a python program to display IMDB’s Top rated 100 Indian movies’ data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "715a46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_top_link = \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\"\n",
    "\n",
    "imdb_top_indian_link = \"https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=461131e5-5af0-4e50-bee2-223fad1e00ca&pf_rd_r=YGMQ7QBSZRY8RE39C7KD&pf_rd_s=center-1&pf_rd_t=60601&pf_rd_i=india.toprated&ref_=fea_india_ss_toprated_india_tr_india250_sm\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "255a448d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.\\n      Anbe Sivam\\n(2003)</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.\\n      Golmaal\\n(1979)</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.\\n      Nayakan\\n(1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.\\n      Jai Bhim\\n(2021)</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.\\n      Pariyerum Perumal\\n(2018)</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.\\n      Baasha\\n(1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.\\n      Baahubali 2: The Conclusion\\n(2017)</td>\n",
       "      <td>2017</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.\\n      Masaan\\n(2015)</td>\n",
       "      <td>2015</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.\\n      Kahaani\\n(2012)</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101.\\n      Dil Chahta Hai\\n(2001)</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title  Year Rating\n",
       "1                      2.\\n      Anbe Sivam\\n(2003)  2003    8.4\n",
       "2                         3.\\n      Golmaal\\n(1979)  1979    8.4\n",
       "3                         4.\\n      Nayakan\\n(1987)  1987    8.4\n",
       "4                        5.\\n      Jai Bhim\\n(2021)  2021    8.4\n",
       "5               6.\\n      Pariyerum Perumal\\n(2018)  2018    8.4\n",
       "..                                              ...   ...    ...\n",
       "96                        97.\\n      Baasha\\n(1995)  1995    8.0\n",
       "97   98.\\n      Baahubali 2: The Conclusion\\n(2017)  2017    8.0\n",
       "98                        99.\\n      Masaan\\n(2015)  2015    8.0\n",
       "99                      100.\\n      Kahaani\\n(2012)  2012    8.0\n",
       "100              101.\\n      Dil Chahta Hai\\n(2001)  2001    8.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_100(imdb_top_indian_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280aa4c6",
   "metadata": {},
   "source": [
    "# 4.Write s python program to display list of respected former presidents of India(i.e. Name , Term of office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15fb3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_presidents_link = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "\n",
    "def india_presidents(link):\n",
    "    site_content = requests.get(link)\n",
    "    india_presidents_soup = BeautifulSoup(site_content.content , \"html.parser\")\n",
    "    scraped_names = india_presidents_soup.find_all(\"h3\")\n",
    "    names = []\n",
    "    for name in scraped_names:\n",
    "        name = name.get_text()\n",
    "        names.append(name)\n",
    "    scraped_p = india_presidents_soup.find_all(\"p\" )\n",
    "    spans = []\n",
    "    for p in scraped_p:\n",
    "        if p.find('span'):\n",
    "            spans.append(p.text)\n",
    "    terms = []\n",
    "    for span in spans[:-1]:\n",
    "        span = span[16:]\n",
    "        terms.append(span)\n",
    "    presidents_of_india = pd.DataFrame()\n",
    "    presidents_of_india[\"Name\"] = names\n",
    "    presidents_of_india['Term'] = terms\n",
    "    \n",
    "    return presidents_of_india\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62300aeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Name  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                                 Term  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10  3 May, 1969 to 20 July, 1969 and 24 August, 19...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_presidents(indian_presidents_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb016c96",
   "metadata": {},
   "source": [
    "# 7. Write a python program to scrape mentioned news details : i) Headline ii) Time iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62811623",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc_link = \"https://www.cnbc.com/world/?region=world\"\n",
    "\n",
    "def get_headlines(link):    \n",
    "    cnbc_site_data = requests.get(link)\n",
    "    cnbc_soup = BeautifulSoup(cnbc_site_data.content , \"html.parser\")\n",
    "    scraped_headlines = cnbc_soup.find_all(\"div\" , class_ = \"RiverPlusCard-container\")\n",
    "    headlines = []\n",
    "    for headline in scraped_headlines:\n",
    "        headline = headline.get_text()\n",
    "        headlines.append(headline)\n",
    "    links = []\n",
    "    for headline in scraped_headlines:\n",
    "        headline = headline.find('a').get('href')\n",
    "        links.append(headline)\n",
    "    scraped_times = cnbc_soup.find_all(\"span\" , class_ = \"RiverByline-datePublished\")\n",
    "    times = []\n",
    "    scraped_headline_rows = cnbc_soup.find_all(\"div\" , class_ = \"RiverPlusCard-container\")\n",
    "    for row in scraped_headline_rows:\n",
    "        row = row.find(\"span\" , class_ = \"RiverByline-datePublished\")\n",
    "        if row == None:\n",
    "            times.append(\"Not available\")\n",
    "        else: times.append(row.get_text())\n",
    "    headline_data = pd.DataFrame()\n",
    "    headline_data['Headline'] = headlines\n",
    "    headline_data['Time posted'] = times\n",
    "    headline_data['Link'] = links\n",
    "    \n",
    "    return(headline_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0469b5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time posted</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dow rebounds to flat, clawing back 200-point l...</td>\n",
       "      <td>22 min ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/04/stock-market-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon to acquire maker of Roomba vacuums for ...</td>\n",
       "      <td>13 min ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/amazon-to-acqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morgan Stanley says tech hasn't hit bottom yet...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goldman Sachs doesn’t see nuclear as a transfo...</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/goldman-doesnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkey's Erdogan meets Putin in Sochi; three s...</td>\n",
       "      <td>13 min ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SolarEdge is willing to sacrifice margins toda...</td>\n",
       "      <td>20 min ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/how-solaredge-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>These companies are still flexing pricing powe...</td>\n",
       "      <td>an hour ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>China halts military, climate ties with U.S. a...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/china-halts-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Santoli: Wall Street holds its breath – and th...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Monkeypox: What to know about the new public h...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/07/26/monkeypox-expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>China, Cairo, Italy: The top ‘travel-inspired’...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/04/what-are-popul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Trump and ex-White House officials likely to b...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/04/trump-and-whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Taiwan's trade with China is far bigger than i...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/taiwans-trade-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hacked crypto startup Nomad offers a 10% bount...</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/crypto-startup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Energy prices have dipped, but oil stocks are ...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/energy-prices-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Malaysia's sovereign wealth fund on why it did...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/04/malaysia-sover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Elon Musk predicts mild 18-month recession, te...</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/04/elon-musk-pred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>International airlines launch battle plans to ...</td>\n",
       "      <td>Not available</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/international-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline    Time posted  \\\n",
       "0   Dow rebounds to flat, clawing back 200-point l...     22 min ago   \n",
       "1   Amazon to acquire maker of Roomba vacuums for ...     13 min ago   \n",
       "2   Morgan Stanley says tech hasn't hit bottom yet...  Not available   \n",
       "3   Goldman Sachs doesn’t see nuclear as a transfo...    3 hours ago   \n",
       "4   Turkey's Erdogan meets Putin in Sochi; three s...     13 min ago   \n",
       "5   SolarEdge is willing to sacrifice margins toda...     20 min ago   \n",
       "6   These companies are still flexing pricing powe...    an hour ago   \n",
       "7   China halts military, climate ties with U.S. a...  Not available   \n",
       "8   Santoli: Wall Street holds its breath – and th...  Not available   \n",
       "9   Monkeypox: What to know about the new public h...  Not available   \n",
       "10  China, Cairo, Italy: The top ‘travel-inspired’...  Not available   \n",
       "11  Trump and ex-White House officials likely to b...  Not available   \n",
       "12  Taiwan's trade with China is far bigger than i...  Not available   \n",
       "13  Hacked crypto startup Nomad offers a 10% bount...    5 hours ago   \n",
       "14  Energy prices have dipped, but oil stocks are ...  Not available   \n",
       "15  Malaysia's sovereign wealth fund on why it did...  Not available   \n",
       "16  Elon Musk predicts mild 18-month recession, te...    3 hours ago   \n",
       "17  International airlines launch battle plans to ...  Not available   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2022/08/04/stock-market-n...  \n",
       "1   https://www.cnbc.com/2022/08/05/amazon-to-acqu...  \n",
       "2                                               /pro/  \n",
       "3   https://www.cnbc.com/2022/08/05/goldman-doesnt...  \n",
       "4   https://www.cnbc.com/2022/08/05/russia-ukraine...  \n",
       "5   https://www.cnbc.com/2022/08/05/how-solaredge-...  \n",
       "6                                               /pro/  \n",
       "7   https://www.cnbc.com/2022/08/05/china-halts-cl...  \n",
       "8                                               /pro/  \n",
       "9   https://www.cnbc.com/2022/07/26/monkeypox-expl...  \n",
       "10  https://www.cnbc.com/2022/08/04/what-are-popul...  \n",
       "11  https://www.cnbc.com/2022/08/04/trump-and-whit...  \n",
       "12  https://www.cnbc.com/2022/08/05/taiwans-trade-...  \n",
       "13  https://www.cnbc.com/2022/08/05/crypto-startup...  \n",
       "14  https://www.cnbc.com/2022/08/05/energy-prices-...  \n",
       "15  https://www.cnbc.com/2022/08/04/malaysia-sover...  \n",
       "16  https://www.cnbc.com/2022/08/04/elon-musk-pred...  \n",
       "17  https://www.cnbc.com/2022/08/05/international-...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_headlines(cnbc_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b3684",
   "metadata": {},
   "source": [
    "# 8. Write a python program to scrape the details of most downloaded articles from AI in last 90 days. \n",
    "i) Paper Title ii) Authors iii) Published Date  iv) Paper URL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6363575",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_link = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "\n",
    "def AI_top_articles(link):\n",
    "    AI_site_data = requests.get(link)\n",
    "    AI_soup = BeautifulSoup(AI_site_data.content , \"html.parser\")\n",
    "    scraped_titles = AI_soup.find_all(\"h2\" , class_ = \"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\")\n",
    "    titles = []\n",
    "    for title in scraped_titles:\n",
    "        title = title.get_text()\n",
    "        titles.append(title)\n",
    "    scraped_authors = AI_soup.find_all(\"span\" , class_ = \"sc-1w3fpd7-0 pgLAT\")\n",
    "    authors = []\n",
    "    for author in scraped_authors:\n",
    "        author = author.get_text()\n",
    "        authors.append(author)\n",
    "    scraped_dates = AI_soup.find_all(\"span\" , class_ = \"sc-1thf9ly-2 bKddwo\")\n",
    "    dates = []\n",
    "    for date in scraped_dates:\n",
    "        date = date.get_text()\n",
    "        dates.append(date)\n",
    "    scraped_links = AI_soup.find_all(\"li\" , class_ = \"sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp\")\n",
    "    links = []\n",
    "    for link in scraped_links:\n",
    "        link = link.find('a').get(\"href\")\n",
    "        links.append(link)\n",
    "    AI_top_articles = pd.DataFrame()\n",
    "    AI_top_articles[\"Paper Title\"] = titles\n",
    "    AI_top_articles['Authors'] = authors\n",
    "    AI_top_articles[\"Publised Date\"] = dates\n",
    "    AI_top_articles[\"Paper URL\"] = links\n",
    "    \n",
    "    return AI_top_articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6754e4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publised Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors   Publised Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_top_articles(AI_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3501d",
   "metadata": {},
   "source": [
    "#  9. Write a python program to scrape mentioned details from dineout.co.in : i) Restaurant name ii) Cuisine iii) Location  iv) Ratingsv) Image URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "517b4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dineout_link = \"https://www.dineout.co.in/hyderabad-restaurants/welcome-back\"\n",
    "\n",
    "def dineout_restaurants(link):\n",
    "    dine_site_data = requests.get(link)\n",
    "    dine_soup = BeautifulSoup(dine_site_data.content , \"html.parser\")\n",
    "    scraped_names = dine_soup.find_all('div' , class_ = \"restnt-info cursor\")\n",
    "    names = []\n",
    "    for name in scraped_names:\n",
    "        name = name.find('a').get_text()\n",
    "        names.append(name)\n",
    "    scraped_cuisines = dine_soup.find_all(\"span\" , class_ = \"double-line-ellipsis\")\n",
    "    cuisines = []\n",
    "    for cuisine in scraped_cuisines:\n",
    "        cuisine = cuisine.find_all('a')\n",
    "        text = \"\"\n",
    "        for a in cuisine:\n",
    "            text = text + ',' + ' ' +  a.get_text()\n",
    "        cuisines.append(text[2:])\n",
    "    scraped_locations = dine_soup.find_all(\"div\" , class_ = \"restnt-loc ellipsis\")\n",
    "    locations = []\n",
    "    for location in scraped_locations:\n",
    "        location = location.find_all('a')\n",
    "        text = \"\"\n",
    "        for a in location:\n",
    "            text = text + ',' + ' ' +  a.get_text().strip(',')\n",
    "        locations.append(text[2:])\n",
    "    scraped_ratings = dine_soup.find_all(\"div\" , class_ = \"restnt-rating rating-4\")\n",
    "    ratings = []\n",
    "    for rating in scraped_ratings:\n",
    "        rating = rating.get_text()\n",
    "        ratings.append(rating)\n",
    "    scraped_images = dine_soup.find_all(\"img\" , class_ = \"no-img\")\n",
    "    images = []\n",
    "    for image in scraped_images:\n",
    "        image = image.get(\"data-src\")\n",
    "        images.append(image)\n",
    "    images\n",
    "    dineout_data = pd.DataFrame()\n",
    "    dineout_data[\"Restaurant Name\"] = names\n",
    "    dineout_data[\"Cuisine\"] = cuisines\n",
    "    dineout_data[\"Location\"] = locations\n",
    "    dineout_data[\"Ratings\"] = ratings\n",
    "    dineout_data[\"Image URL\"] = images\n",
    "\n",
    "    return dineout_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1e6f7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ohri's Jiva</td>\n",
       "      <td>North Indian, Chinese, Rajasthani, South Indian</td>\n",
       "      <td>White House, Begumpet, Secunderabad</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krishnapatnam</td>\n",
       "      <td>Andhra, South Indian, Mughlai</td>\n",
       "      <td>Shreshta Aura, Jubilee Hills, Central West Hyd...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Headquarters</td>\n",
       "      <td>Chinese, Continental, North Indian</td>\n",
       "      <td>Somajiguda, Central East Hyderabad</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABs - Absolute Barbecues</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amogham - The Lake View Restaurant</td>\n",
       "      <td>Chinese, North Indian, Continental, Mughlai</td>\n",
       "      <td>Khairatabad, Central Hyderabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 Downing Street</td>\n",
       "      <td>Finger Food, Chinese, Continental, North Indian</td>\n",
       "      <td>Lifestyle Building, Begumpet, Secunderabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Exotica</td>\n",
       "      <td>North Indian, Chinese, Asian</td>\n",
       "      <td>12th Square Building, Banjara Hills, Central E...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barbeque Nation</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>ANR Center, Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABs - Absolute Barbecues</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>SD Road, Secunderabad</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>By The Bay - Bar Exchange</td>\n",
       "      <td>North Indian, Continental, Chinese</td>\n",
       "      <td>Khairatabad, Central Hyderabad</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A'La Liberty</td>\n",
       "      <td>North Indian, Chinese, Mexican</td>\n",
       "      <td>Leela Gopal Towers, Banjara Hills, Central Eas...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bikanervala</td>\n",
       "      <td>North Indian, Street Food, Fast Food</td>\n",
       "      <td>Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Parampara - Flavours of india</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>ANR Center, Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Verandah</td>\n",
       "      <td>Chinese, North Indian, Continental, Italian</td>\n",
       "      <td>The Park, Somajiguda, Central East Hyderabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hard Rock Cafe</td>\n",
       "      <td>Continental, American, Fast Food</td>\n",
       "      <td>GVK One Mall, Banjara Hills, Central East Hyde...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>Pizza, Fast Food</td>\n",
       "      <td>The Grand Building, Somajiguda, Central East H...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Seven Spices</td>\n",
       "      <td>Andhra, Biryani</td>\n",
       "      <td>Somajiguda, Central East Hyderabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Krishnapatnam</td>\n",
       "      <td>South Indian, Andhra, Mughlai</td>\n",
       "      <td>Forum Sujana Mall, Kukatpally, West Hyderabad</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Eagles Pizza</td>\n",
       "      <td>Pizza, Fast Food</td>\n",
       "      <td>Ohud Building, Somajiguda, Central East Hyderabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hashi Izakaya - Asian Bar &amp; Kitchen</td>\n",
       "      <td>Chinese, Thai, Japanese</td>\n",
       "      <td>Country Club Complex, Begumpet, Secunderabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cream Stone</td>\n",
       "      <td>Desserts, Beverages</td>\n",
       "      <td>The Platinum Hotel, Himayath Nagar, Central Hy...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Restaurant Name  \\\n",
       "0                           Ohri's Jiva   \n",
       "1                         Krishnapatnam   \n",
       "2                          Headquarters   \n",
       "3              ABs - Absolute Barbecues   \n",
       "4    Amogham - The Lake View Restaurant   \n",
       "5                     10 Downing Street   \n",
       "6                               Exotica   \n",
       "7                       Barbeque Nation   \n",
       "8              ABs - Absolute Barbecues   \n",
       "9             By The Bay - Bar Exchange   \n",
       "10                         A'La Liberty   \n",
       "11                          Bikanervala   \n",
       "12        Parampara - Flavours of india   \n",
       "13                             Verandah   \n",
       "14                       Hard Rock Cafe   \n",
       "15                            Pizza Hut   \n",
       "16                         Seven Spices   \n",
       "17                        Krishnapatnam   \n",
       "18                         Eagles Pizza   \n",
       "19  Hashi Izakaya - Asian Bar & Kitchen   \n",
       "20                          Cream Stone   \n",
       "\n",
       "                                            Cuisine  \\\n",
       "0   North Indian, Chinese, Rajasthani, South Indian   \n",
       "1                     Andhra, South Indian, Mughlai   \n",
       "2                Chinese, Continental, North Indian   \n",
       "3                                      North Indian   \n",
       "4       Chinese, North Indian, Continental, Mughlai   \n",
       "5   Finger Food, Chinese, Continental, North Indian   \n",
       "6                      North Indian, Chinese, Asian   \n",
       "7                             North Indian, Chinese   \n",
       "8                                      North Indian   \n",
       "9                North Indian, Continental, Chinese   \n",
       "10                   North Indian, Chinese, Mexican   \n",
       "11             North Indian, Street Food, Fast Food   \n",
       "12                            Chinese, North Indian   \n",
       "13      Chinese, North Indian, Continental, Italian   \n",
       "14                 Continental, American, Fast Food   \n",
       "15                                 Pizza, Fast Food   \n",
       "16                                  Andhra, Biryani   \n",
       "17                    South Indian, Andhra, Mughlai   \n",
       "18                                 Pizza, Fast Food   \n",
       "19                          Chinese, Thai, Japanese   \n",
       "20                              Desserts, Beverages   \n",
       "\n",
       "                                             Location Ratings  \\\n",
       "0                 White House, Begumpet, Secunderabad       4   \n",
       "1   Shreshta Aura, Jubilee Hills, Central West Hyd...     3.9   \n",
       "2                  Somajiguda, Central East Hyderabad     4.1   \n",
       "3               Banjara Hills, Central East Hyderabad     4.3   \n",
       "4                      Khairatabad, Central Hyderabad     3.8   \n",
       "5          Lifestyle Building, Begumpet, Secunderabad     4.3   \n",
       "6   12th Square Building, Banjara Hills, Central E...     4.4   \n",
       "7   ANR Center, Banjara Hills, Central East Hyderabad     4.2   \n",
       "8                               SD Road, Secunderabad     4.1   \n",
       "9                      Khairatabad, Central Hyderabad     4.1   \n",
       "10  Leela Gopal Towers, Banjara Hills, Central Eas...       4   \n",
       "11              Banjara Hills, Central East Hyderabad     4.2   \n",
       "12  ANR Center, Banjara Hills, Central East Hyderabad       4   \n",
       "13       The Park, Somajiguda, Central East Hyderabad     3.9   \n",
       "14  GVK One Mall, Banjara Hills, Central East Hyde...     4.3   \n",
       "15  The Grand Building, Somajiguda, Central East H...     4.4   \n",
       "16                 Somajiguda, Central East Hyderabad     4.2   \n",
       "17      Forum Sujana Mall, Kukatpally, West Hyderabad     3.7   \n",
       "18  Ohud Building, Somajiguda, Central East Hyderabad     3.9   \n",
       "19       Country Club Complex, Begumpet, Secunderabad     4.2   \n",
       "20  The Platinum Hotel, Himayath Nagar, Central Hy...     4.3   \n",
       "\n",
       "                                            Image URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dineout_restaurants(dineout_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783227c",
   "metadata": {},
   "source": [
    "# 10. Write a python program to scrape the details of top publications from Google Scholar? i) Rank ii) Publicationiii) h5-index iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b261ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_link = \"https://scholar.google.com/citations?view_op=top_venues&hl=en\"\n",
    "\n",
    "def google_publications(link):\n",
    "    google_site_data = requests.get(link)\n",
    "    google_soup = BeautifulSoup(google_site_data.content , \"html.parser\")\n",
    "\n",
    "    scraped_ranks = google_soup.find_all(\"td\" , class_ = \"gsc_mvt_p\")\n",
    "    scraped_publication = google_soup.find_all(\"td\" , class_ = \"gsc_mvt_t\")\n",
    "    scraped_index = google_soup.find_all(\"a\" , class_ = \"gs_ibl gsc_mp_anchor\")\n",
    "    scraped_median = google_soup.find_all(\"span\" , class_ = \"gs_ibl gsc_mp_anchor\")\n",
    "    publications = []\n",
    "    ranks = []\n",
    "    indexs = []\n",
    "    medians = []\n",
    "    for rank in scraped_ranks:\n",
    "        rank = rank.get_text()\n",
    "        ranks.append(rank)\n",
    "    for publication in scraped_publication:\n",
    "        publication = publication.get_text()\n",
    "        publications.append(publication)\n",
    "    for index in scraped_index:\n",
    "        index = index.get_text()\n",
    "        indexs.append(index)\n",
    "    for median in scraped_median:\n",
    "        median = median.get_text()\n",
    "        medians.append(median)\n",
    "    google_data = pd.DataFrame()\n",
    "    google_data[\"Rank\"] = ranks\n",
    "    google_data[\"Publication\"] = publications\n",
    "    google_data[\"H5-index\"] = indexs\n",
    "    google_data[\"H5-median\"] = medians\n",
    "\n",
    "    return google_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe291f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>H5-index</th>\n",
       "      <th>H5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication H5-index H5-median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_publications(google_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ceddb4",
   "metadata": {},
   "source": [
    "# 5. Write a python program to scrape cricket rankings from icc-cricket.com.- To scrape the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ba426",
   "metadata": {},
   "outputs": [],
   "source": [
    " #5).a)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "835d82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_men_link = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "batting_men_link = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "bowling_men_link = \"https://www.icc-cricket.com/rankings/mens/player-rankings\"\n",
    "\n",
    "\n",
    "\n",
    "def top_10_odi_teams_men(link) : \n",
    "    site_data_team_men = requests.get(link)\n",
    "\n",
    "    soup_team_men = BeautifulSoup(site_data_team_men.content, \"html.parser\")\n",
    "\n",
    "    scraped_teams_men = soup_team_men.find_all(\"span\" , class_ = \"u-hide-phablet\")\n",
    "\n",
    "    teams_men = []\n",
    "    for team in scraped_teams_men:\n",
    "        team = team.get_text()\n",
    "        teams_men.append(team)\n",
    "\n",
    "    scraped_team_men_matches = soup_team_men.find_all(\"td\" , class_ = \"table-body__cell u-center-text\" )\n",
    "\n",
    "    matches_men =  []\n",
    "    matches_men.append('15')\n",
    "\n",
    "    for match in scraped_team_men_matches:\n",
    "        if scraped_team_men_matches.index(match) % 2  == 0 :\n",
    "            match = match.get_text()\n",
    "            matches_men.append(match)\n",
    "\n",
    "    points_men =  []\n",
    "    points_men.append('1913')\n",
    "\n",
    "    for match in scraped_team_men_matches:\n",
    "        if scraped_team_men_matches.index(match) % 2  == 1 :\n",
    "            match = match.get_text()\n",
    "            points_men.append(match)\n",
    "\n",
    "    ratings_men =  []\n",
    "    ratings_men.append('128')\n",
    "\n",
    "    scraped_team_men_ratings = soup_team_men.find_all(\"td\" , class_ = \"table-body__cell u-text-right rating\" )\n",
    "\n",
    "    for rating in scraped_team_men_ratings:\n",
    "        rating = rating.get_text()\n",
    "        ratings_men.append(rating)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    data[\"Team\"] = teams_men\n",
    "    data[\"Matches\"] = matches_men\n",
    "    data['Points'] = points_men\n",
    "    data[\"Rating\"] = ratings_men\n",
    "\n",
    "    top_10_odi_teams_men = data[0:11]\n",
    "\n",
    "    return (top_10_odi_teams_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "883a701d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>15</td>\n",
       "      <td>1913</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>28</td>\n",
       "      <td>3,085</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>19</td>\n",
       "      <td>2,005</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,325</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>27</td>\n",
       "      <td>2,639</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,621</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>23</td>\n",
       "      <td>1,214</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points Rating\n",
       "0    New Zealand      15   1913    128\n",
       "1        England      27  3,226    119\n",
       "2          India      28  3,085    110\n",
       "3       Pakistan      19  2,005    106\n",
       "4      Australia      23  2,325    101\n",
       "5   South Africa      21  2,111    101\n",
       "6     Bangladesh      27  2,639     98\n",
       "7      Sri Lanka      29  2,658     92\n",
       "8    West Indies      38  2,621     69\n",
       "9    Afghanistan      18  1,238     69\n",
       "10       Ireland      23  1,214     53"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_odi_teams_men(team_men_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd678caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # 5. b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e737035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_odi_batsmen(link):\n",
    "\n",
    "    site_data_5b = requests.get(link)\n",
    "\n",
    "    soup_5b = BeautifulSoup(site_data_5b.content ,\"html.parser\" )\n",
    "\n",
    "    players = []\n",
    "    teams = []\n",
    "    ratings = []\n",
    "\n",
    "    top_player = soup_5b.find(\"div\" , class_ = \"rankings-block__banner--name-large\")\n",
    "    players.append(top_player.get_text())\n",
    "\n",
    "    top_team = soup_5b.find(\"div\" , class_ = \"rankings-block__banner--nationality\")\n",
    "    teams.append(top_team.get_text().strip())\n",
    "\n",
    "    top_rating = soup_5b.find(\"div\" , class_ = \"rankings-block__banner--rating\")\n",
    "    ratings.append(top_rating.get_text())\n",
    "\n",
    "    scraped_players_5b = soup_5b.find_all(\"td\" , class_ = \"table-body__cell rankings-table__name name\" )\n",
    "\n",
    "    for player in scraped_players_5b:\n",
    "        player = player.get_text().strip()\n",
    "        players.append(player)\n",
    "\n",
    "    scraped_teams_5b = soup_5b.find_all(\"span\" , class_ = \"table-body__logo-text\" )\n",
    "\n",
    "    for team in scraped_teams_5b:\n",
    "        team = team.get_text().strip()\n",
    "        teams.append(team)\n",
    "\n",
    "    scraped_ratings_5b = soup_5b.find_all(\"td\" , class_ = \"table-body__cell rating\" )\n",
    "\n",
    "    for rating in scraped_ratings_5b:\n",
    "        rating = rating.get_text().strip()\n",
    "        ratings.append(rating)\n",
    "\n",
    "    data_5b = pd.DataFrame()\n",
    "    data_5b[\"Player\"] = players\n",
    "    data_5b[\"team\"] = teams\n",
    "    data_5b[\"Rating\"] = ratings\n",
    "    top_odi_batsmen = data_5b[:10]\n",
    "    \n",
    "    \n",
    "    return top_odi_batsmen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a4f181c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player team Rating\n",
       "0             Babar Azam  PAK    892\n",
       "1            Imam-ul-Haq  PAK    815\n",
       "2  Rassie van der Dussen   SA    789\n",
       "3        Quinton de Kock   SA    784\n",
       "4            Virat Kohli  IND    767\n",
       "5           Rohit Sharma  IND    763\n",
       "6            Ross Taylor   NZ    744\n",
       "7           David Warner  AUS    737\n",
       "8         Jonny Bairstow  ENG    732\n",
       "9            Aaron Finch  AUS    715"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_batsmen(batting_men_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e93dac",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 5. c)Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01806ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_odi_bowlers(link):\n",
    "\n",
    "    site_data_5c = requests.get(link)\n",
    "\n",
    "    soup_5c = BeautifulSoup(site_data_5c.content ,\"html.parser\" )\n",
    "\n",
    "    players_5c = []\n",
    "    teams_5c = []\n",
    "    ratings_5c = []\n",
    "\n",
    "    top_player_5c = soup_5c.find(\"div\" , class_ = \"rankings-block__banner--name-large\")\n",
    "    players_5c.append(top_player_5c.get_text())\n",
    "\n",
    "    top_team_5c = soup_5c.find(\"div\" , class_ = \"rankings-block__banner--nationality\")\n",
    "    teams_5c.append(top_team_5c.get_text().strip())\n",
    "\n",
    "    top_rating_5c = soup_5c.find(\"div\" , class_ = \"rankings-block__banner--rating\")\n",
    "    ratings_5c.append(top_rating_5c.get_text())\n",
    "\n",
    "    scraped_players_5c = soup_5c.find_all(\"td\" , class_ = \"table-body__cell rankings-table__name name\" )\n",
    "\n",
    "    for player in scraped_players_5c:\n",
    "        player = player.get_text().strip()\n",
    "        players_5c.append(player)\n",
    "\n",
    "        \n",
    "    scraped_teams_5c = soup_5c.find_all(\"td\" , class_ = \"table-body__cell nationality-logo rankings-table__team\" )\n",
    "\n",
    "    for team in scraped_teams_5c:\n",
    "        team = team.get_text().strip()\n",
    "        teams_5c.append(team)\n",
    "\n",
    "\n",
    "    scraped_ratings_5c = soup_5c.find_all(\"td\" , class_ = \"table-body__cell rating\" )\n",
    "\n",
    "    for rating in scraped_ratings_5c:\n",
    "        rating = rating.get_text().strip()\n",
    "        ratings_5c.append(rating)\n",
    "\n",
    "    data_5c = pd.DataFrame()\n",
    "\n",
    "    data_5c[\"Player\"] = players_5c\n",
    "    data_5c[\"team\"] = teams_5c\n",
    "    data_5c[\"Rating\"] = ratings_5c\n",
    "\n",
    "    top_odi_bowlers = data_5c[:10]\n",
    "    \n",
    "    return top_odi_bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "507e2a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player team Rating\n",
       "0       Trent Boult   NZ    697\n",
       "1    Jasprit Bumrah  IND    682\n",
       "2    Shaheen Afridi  PAK    681\n",
       "3    Josh Hazlewood  AUS    679\n",
       "4  Mujeeb Ur Rahman  AFG    676\n",
       "5      Mehedi Hasan  BAN    672\n",
       "6        Matt Henry   NZ    663\n",
       "7     Mohammad Nabi  AFG    657\n",
       "8       Rashid Khan  AFG    651\n",
       "9      Chris Woakes  ENG    640"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_bowlers(bowling_men_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0a8fc",
   "metadata": {},
   "source": [
    "# 6. Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape the following ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "728b63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_women_link = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "batting_women_link = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "bowling_women_link = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad20f13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>15</td>\n",
       "      <td>1913</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>33</td>\n",
       "      <td>4,046</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,219</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>3,019</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>30</td>\n",
       "      <td>2,768</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>8</td>\n",
       "      <td>351</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points Rating\n",
       "0      Australia      15   1913    128\n",
       "1        England      33  4,046    123\n",
       "2   South Africa      35  4,157    119\n",
       "3          India      32  3,219    101\n",
       "4    New Zealand      31  3,019     97\n",
       "5    West Indies      30  2,768     92\n",
       "6     Bangladesh      12    930     78\n",
       "7       Pakistan      30  1,962     65\n",
       "8      Sri Lanka      11    495     45\n",
       "9        Ireland       8    351     44\n",
       "10      Zimbabwe       8      0      0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_odi_teams_men(team_women_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 6).b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16e37dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player team Rating\n",
       "0         Alyssa Healy  AUS    785\n",
       "1          Beth Mooney  AUS    749\n",
       "2       Natalie Sciver  ENG    747\n",
       "3      Laura Wolvaardt   SA    732\n",
       "4          Meg Lanning  AUS    710\n",
       "5       Rachael Haynes  AUS    701\n",
       "6    Amy Satterthwaite   NZ    681\n",
       "7       Tammy Beaumont  ENG    667\n",
       "8  Chamari Athapaththu   SL    655\n",
       "9      Smriti Mandhana  IND    649"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_batsmen(batting_women_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a214e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 6) c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acb2a9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rajeshwari Gayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player team Rating\n",
       "0    Sophie Ecclestone  ENG    761\n",
       "1        Jess Jonassen  AUS    725\n",
       "2         Megan Schutt  AUS    722\n",
       "3       Shabnim Ismail   SA    722\n",
       "4       Jhulan Goswami  IND    644\n",
       "5       Ayabonga Khaka   SA    634\n",
       "6  Rajeshwari Gayakwad  IND    613\n",
       "7      Hayley Matthews   WI    612\n",
       "8      Katherine Brunt  ENG    601\n",
       "9       Marizanne Kapp   SA    598"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_bowlers(bowling_women_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
